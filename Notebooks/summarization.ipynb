{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c723d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fac8791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\PROJECT\\AI-Powered Visual Report Generator\\AI-Powered-Visual-Report-Generator\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b42688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_API_KEY']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c205595",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"\")\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9961fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6199584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the base path where the folders are located\n",
    "base_path = 'D:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Notebooks/All_Graphs/'\n",
    "\n",
    "# Automatically list directories in the base path\n",
    "folders = [folder for folder in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, folder))]\n",
    "\n",
    "# Initialize your model here\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Path to save the summaries\n",
    "summary_file_path = 'D:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Notebooks/summaries_3.txt'\n",
    "\n",
    "# Function to generate summary for a given image\n",
    "def generate_summary(image_path):\n",
    "    # Open the image\n",
    "    img = PIL.Image.open(image_path)\n",
    "    \n",
    "    # Here, you should replace the following line with your actual model call to generate the summary\n",
    "    response = model.generate_content(img)\n",
    "    summary = response.text  # This is where you'd extract the summary from your model's response\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Write summaries to the file, specifying UTF-8 encoding to avoid UnicodeEncodeError\n",
    "with open(summary_file_path, 'w', encoding='utf-8') as summary_file:\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.png'):\n",
    "                image_path = os.path.join(folder_path, filename)\n",
    "                \n",
    "                # Generate summary for the image\n",
    "                summary = generate_summary(image_path)\n",
    "                \n",
    "                # Write the summary to the file\n",
    "                summary_file.write(f\"Summary of {filename} in {folder}:\\n{summary}\\n\\n\")\n",
    "\n",
    "print(\"Summaries generated and saved to\", summary_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574fae37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: 'D:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Outputs/summaries2.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m base_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Outputs/summaries2.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Automatically list directories in the base path\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m folders \u001b[38;5;241m=\u001b[39m [folder \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, folder))]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize your model here - Adjusted for text processing\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini-pro-text\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Assuming there's a suitable model for text\u001b[39;00m\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: 'D:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Outputs/summaries2.txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the base path where the folders with text files are located\n",
    "base_path = 'D:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Outputs/summaries2.txt'\n",
    "\n",
    "# Automatically list directories in the base path\n",
    "folders = [folder for folder in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, folder))]\n",
    "\n",
    "# Initialize your model here - Adjusted for text processing\n",
    "model = genai.GenerativeModel('gemini-pro-text')  # Assuming there's a suitable model for text\n",
    "\n",
    "# Path to save the summaries\n",
    "summary_file_path = 'D:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Out[uts/Final_summary.txt'\n",
    "\n",
    "# Function to generate summary for a given text file\n",
    "def generate_summary(text_content):\n",
    "    # Here, replace the line with your actual model call to generate the summary from text content\n",
    "    response = model.generate_content({\"type\": \"text\", \"content\": text_content})\n",
    "    summary = response.text  # Extract the summary from your model's response\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Write summaries to the file, specifying UTF-8 encoding to avoid UnicodeEncodeError\n",
    "with open(summary_file_path, 'w', encoding='utf-8') as summary_file:\n",
    "    for folder in folders:\n",
    "        summaries = []  # Collect summaries for each folder to combine them later\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.txt'):  # Adjust to process .txt files\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    text_content = file.read().strip()\n",
    "                \n",
    "                # Generate summary for the text content\n",
    "                summary = generate_summary(text_content)\n",
    "                summaries.append(summary)\n",
    "        \n",
    "        # Combine all summaries for this folder into one paragraph\n",
    "        combined_summary = \" \".join(summaries)\n",
    "        \n",
    "        # Write the combined summary to the file\n",
    "        summary_file.write(f\"Combined summary for {folder}:\\n{combined_summary}\\n\\n\")\n",
    "\n",
    "print(\"Summaries generated and saved to\", summary_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8911e8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini API configured successfully.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "api_key = ''\n",
    "\n",
    "try:\n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"Gemini API configured successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error configuring Gemini API: {e}. Please ensure your API key is valid.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "354e2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a44d75f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: GOOGLE_API_KEY environment variable not set.\n",
      "Error during summarization: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "Summary generated and saved to 'D:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Outputs/Final_Report.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Your API key should already be configured at this point.\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"Error: GOOGLE_API_KEY environment variable not set.\")\n",
    "else:\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: '{file_path}'\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def generate_summary_for_file(text_content, filename=\"\"):\n",
    "    if not text_content.strip():\n",
    "        return \"No content to summarize for this file.\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Create a concise summary from the following text, which describes graph data or insights.\n",
    "    Focus on the main subject, key data points, and observed trends.\n",
    "    {f\"This summary is for the content from file: {filename}.\" if filename else \"\"}\n",
    "    Text to summarize:\n",
    "    {text_content}\n",
    "    Concise Summary:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        summary = response.text\n",
    "        return summary.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during summarization: {e}\")\n",
    "        return f\"Summarization failed: {e}\"\n",
    "\n",
    "# Set your file directly (no input to avoid kernel issues)\n",
    "input_file_path = 'D:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Outputs/summaries2.txt'\n",
    "summary_file_path = 'D:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Outputs/Final_Report.txt'\n",
    "\n",
    "if not os.path.isfile(input_file_path):\n",
    "    print(f\"Error: The file '{input_file_path}' does not exist.\")\n",
    "else:\n",
    "    file_content = read_text_file(input_file_path)\n",
    "    if file_content:\n",
    "        final_summary_report = generate_summary_for_file(file_content, os.path.basename(input_file_path))\n",
    "        try:\n",
    "            with open(summary_file_path, 'w', encoding='utf-8') as summary_file:\n",
    "                summary_file.write(f\"--- Summary Report for File: '{os.path.basename(input_file_path)}' ---\\n\")\n",
    "                summary_file.write(f\"{final_summary_report}\\n\\n\")\n",
    "            print(f\"Summary generated and saved to '{summary_file_path}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing summary: {e}\")\n",
    "    else:\n",
    "        print(\"No content to summarize.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ec69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.isfile('D:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Outputs/Final_Report.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e64f996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.5\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "print(genai.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46f69b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-04-17\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash-preview-04-17-thinking\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/veo-2.0-generate-001\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog-rai-v3\n",
      "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
      "models/gemini-2.0-flash-live-001\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "models = genai.list_models()\n",
    "for m in models:\n",
    "    print(m.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5668c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during summarization: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 18\n",
      "}\n",
      "]\n",
      "Summary generated and saved to 'D:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Outputs/Final_Report.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Your API key (hardcoded for now)\n",
    "api_key = ''\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Use the correct model name\n",
    "model = genai.GenerativeModel('models/gemini-1.5-pro')\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read().strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def generate_summary_for_file(text_content, filename=\"\"):\n",
    "    if not text_content.strip():\n",
    "        return \"No content to summarize for this file.\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Create a concise summary from the following text, which describes graph data or insights.\n",
    "    Focus on the main subject, key data points, and observed trends.\n",
    "    {f\"This summary is for the content from file: {filename}.\" if filename else \"\"}\n",
    "    Text to summarize:\n",
    "    {text_content}\n",
    "    Concise Summary:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during summarization: {e}\")\n",
    "        return f\"Summarization failed: {e}\"\n",
    "\n",
    "# File paths\n",
    "input_file_path = 'D:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Outputs/summaries2.txt'\n",
    "summary_file_path = 'D:/Desktop/PROJECT/AI-Powered Visual Report Generator/AI-Powered-Visual-Report-Generator/Outputs/Final_Report.txt'\n",
    "\n",
    "if not os.path.isfile(input_file_path):\n",
    "    print(\"File not found. Please check your file path.\")\n",
    "else:\n",
    "    file_content = read_text_file(input_file_path)\n",
    "    if file_content:\n",
    "        final_summary_report = generate_summary_for_file(file_content, os.path.basename(input_file_path))\n",
    "        try:\n",
    "            with open(summary_file_path, 'w', encoding='utf-8') as summary_file:\n",
    "                summary_file.write(f\"--- Summary Report for File: '{os.path.basename(input_file_path)}' ---\\n\")\n",
    "                summary_file.write(f\"{final_summary_report}\\n\\n\")\n",
    "            print(f\"Summary generated and saved to '{summary_file_path}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing summary: {e}\")\n",
    "    else:\n",
    "        print(\"No content to summarize.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15228a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\PROJECT\\AI-Powered Visual Report Generator\\AI-Powered-Visual-Report-Generator\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf1d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
